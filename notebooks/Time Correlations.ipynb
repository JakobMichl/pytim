{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pytim\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "from pytim.datafiles import pytim_data, WATERSMALL_GRO\n",
    "from pytim.utilities import lap\n",
    "from pytim.observables import Correlator, Velocity\n",
    "from matplotlib import pyplot as plt\n",
    "#import deepdiff\n",
    "from pytim import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAJ = pytim_data.fetch('WATERSMALL_LONG_TRR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = mda.Universe(WATERSMALL_GRO,TRAJ)\n",
    "g = u.select_atoms('name OW ')\n",
    "inter = pytim.ITIM(u,group=g,molecular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: the group of which we want to compute the autocorrelations \n",
    "# will be passed later as an imput to the correlate() methot.\n",
    "\n",
    "# velocity autocorrelation, consider all 3 spatial directions\n",
    "total_vv = Correlator(observable=Velocity())\n",
    "# velocity autocorrelation in the xy plane, use group g as a reference group \n",
    "layer_vv = Correlator(observable=Velocity('xy'), reference=g)\n",
    "# survival probability\n",
    "layer_nn = Correlator(reference=g)\n",
    "\n",
    "\n",
    "for t in u.trajectory[1:4000]:\n",
    "    if t.frame % 100 == 0:\n",
    "        print t.frame,\n",
    "    # velocity correlation of the whole set of oxygen atoms\n",
    "    total_vv.sample(g)\n",
    "    # velocity correlation of the surface atoms\n",
    "    layer_vv.sample(inter.atoms)\n",
    "    # survival probability in the first group\n",
    "    layer_nn.sample(inter.atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# after the sampling of the time series is over, we compute the correlations:\n",
    "\n",
    "vacf_total = total_vv.correlation()\n",
    "\n",
    "# in the reentrant variant, leaving the layer does not interrupt the contribution\n",
    "# to the autocorrelation function\n",
    "vacf_layer = layer_vv.correlation(reentrant=True) \n",
    "vacf_layer_nr = layer_vv.correlation(reentrant=False) \n",
    "survival = layer_nn.correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lim = 500\n",
    "time = u.trajectory[1].time * np.arange(lim)\n",
    "\n",
    "plt.plot(time,vacf_total[:lim],label='total')\n",
    "plt.plot(time,vacf_layer[:lim],'.',label='in-layer, reentrant')\n",
    "plt.plot(time,vacf_layer_nr[:lim],'-',label='in-layer, non reentrant')\n",
    "plt.plot(time,survival[:lim],label='survival probability, reentrant')\n",
    "plt.plot(time,time*0,c='black')\n",
    "\n",
    "plt.xlabel('time / ps')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking presence of a cached copy ... found \n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import pytim\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "from pytim.datafiles import pytim_data, WATERSMALL_GRO\n",
    "from pytim.utilities import lap\n",
    "from pytim.observables import Correlator, Velocity\n",
    "from matplotlib import pyplot as plt\n",
    "#import deepdiff\n",
    "from pytim import utilities\n",
    "TRAJ = pytim_data.fetch('WATERSMALL_LONG_TRR')\n",
    "u = mda.Universe(WATERSMALL_GRO,TRAJ)\n",
    "g = u.select_atoms('name OW ')\n",
    "inter = pytim.ITIM(u,group=g,molecular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AtomGroup with 2 atoms>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bv =  Correlator(observable=Velocity('xy'))\n",
    "vv = Correlator(observable=Velocity('x'), reference=g[0:2])\n",
    "vvv = Correlator(observable=Velocity('xy'), reference=g[0:2])\n",
    "nn = Correlator(reference=g[0:2])\n",
    "g[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g[0:2].velocities*=0.0\n",
    "g[0:2].velocities+=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[:2].velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv.sample(g[:2])\n",
    "#bv.sample(g[:2])\n",
    "vvv.sample(g[:2])\n",
    "nn.sample(g[:2])\n",
    "\n",
    "vv.sample(g[:1])\n",
    "nn.sample(g[:1])\n",
    "vvv.sample(g[:1])\n",
    "#bv.sample(g[:2])\n",
    "\n",
    "g[0:2].velocities/=2\n",
    "vv.sample(g[:2])\n",
    "nn.sample(g[:2])\n",
    "vvv.sample(g[:2])\n",
    "#bv.sample(g[:2])\n",
    "\n",
    "#vv.sample(g[:2])\n",
    "#nn.sample(g[:2])\n",
    "\n",
    "#vv.sample(g[:1])\n",
    "#nn.sample(g[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  0.667],\n",
       "       [ 1.   , -0.   ],\n",
       "       [ 1.   ,  1.   ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions()\n",
    "\n",
    "a=nn.correlation(reduced=False,normalized=False,intermittent=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1.0], [1.0, -0.0], [0.5, 0.5]]\n",
      "[[True, True], [True, False], [True, True]]\n"
     ]
    }
   ],
   "source": [
    "print vv.timeseries\n",
    "print nn.maskseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[1.,2.,3./2.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u = mda.Universe(WATER_GRO)\n",
    "g=u.atoms[0:2]\n",
    "g.velocities*=0.0\n",
    "g.velocities+=1.0\n",
    "C = {}\n",
    "C['vv-x'] = Correlator(observable=Velocity('x', reference=g)) \n",
    "C['vv-xy']= Correlator(observable=Velocity('xy', reference=g))\n",
    "C['nn']   = Correlator(reference=g)\n",
    "\n",
    "for name,c in C.iteritems():\n",
    "    print 'sampling',name\n",
    "    c.sample(g)\n",
    "    c.sample(g[:1])\n",
    "    c.sample(g)\n",
    "\n",
    "print C['nn'].maskseries\n",
    "print C['vv-x'].timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print correlation_(nn,reduced=False,normalized=False,intermittent=True)\n",
    "print correlation_(nn,reduced=True,normalized=False,intermittent=True)\n",
    "print correlation_(nn,reduced=True,normalized=True,intermittent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_intermittent(nn,reduced=False,normalized=False),\"\\n\"\n",
    "print nn.corr\n",
    "print nn.norm\n",
    "print np.average(nn.maskseries,axis=0)\n",
    "print \"---\"\n",
    "print nn.corr*nn.norm #/np.average(nn.maskseries,axis=0)\n",
    "print 1+np.arange(1.*nn.norm.shape[0])[::-1]\n",
    "print  nn.corr/(nn.norm/(1+np.arange(nn.norm.shape[0])[::-1]).reshape(3,1))\n",
    "print (nn.norm/(1+np.arange(nn.norm.shape[0])[::-1]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nn.maskseries\n",
    "print nn.corr\n",
    "print np.average(np.cumsum(nn.maskseries,axis=0),axis=1)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(100*np.random.random(int(1e6)),dtype=np.int)\n",
    "#print test\n",
    "%timeit np.cumsum(test)[::-1]\n",
    "%timeit 1.*np.cumsum(test)[::-1]\n",
    "%timeit np.cumsum(test,dtype=np.float)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(test,dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.arange(int(1e5))\n",
    "%timeit 1+np.arange(int(1e5))\n",
    "%timeit 1.+np.arange(int(1e5))\n",
    "%timeit 1.+np.arange(1.+1e5)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit test.reshape(1000000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nn.maskseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fft.fft(nn.maskseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(nn.maskseries)\n",
    "fa1 = np.fft.fft(nn.maskseries, axis=0, n= size * 2)\n",
    "print fa1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.arange(size)[::-1] + 1.\n",
    "print np.fft.fft(fa1*np.conj(fa1),axis=0)[:size]\n",
    "print norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.fft.fft(fa1*np.conj(fa1),axis=0).real[:size]/norm.reshape(norm.shape[0],1)/(2*size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print fa1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nn.nseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[False]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nn.maskseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print [[not i and i  for i in nn.maskseries[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[False for i in nn.maskseries[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[False] * len(nn.maskseries[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nn.maskseries\n",
    "print np.average([nn.maskseries[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/np.average(np.array([1]*3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.random.random(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.fft.fft(a)\n",
    "%timeit np.cumsum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def determine_dimension(self):\n",
    "        self.nseries = max(len(self.timeseries),len(self.maskseries))\n",
    "\n",
    "        if len(self.shape) == 1:\n",
    "            shape = (self.nseries, self.shape[0], 1)\n",
    "            dim = 1\n",
    "        elif len(self.shape) == 2:\n",
    "            shape = (self.nseries, self.shape[0] , self.shape[1])\n",
    "            dim = self.shape[1]\n",
    "        else:\n",
    "            raise RuntimeError(\"Correlations of tensorial quantites not allowed in \"+self.name)\n",
    "        return dim\n",
    "  \n",
    "    def survival_probability(self,ms,normalized,reduced,intermittent):\n",
    "        if intermittent == True:\n",
    "            corr, norm = survival_intermittent(self,ms,normalized)\n",
    "        else:\n",
    "            corr, norm = survival_continuous(self,ms,normalized)\n",
    "                \n",
    "        if reduced == True:\n",
    "            corr = np.average(corr,axis=1)\n",
    "            if normalized == True:\n",
    "                corr /= np.average(norm,axis=1)\n",
    "        elif normalized == True:\n",
    "            corr /= norm\n",
    "            \n",
    "        return corr\n",
    "    \n",
    "\n",
    "    def survival_intermittent(self,ms,normalized):\n",
    "        norm  = None\n",
    "        corr = utilities.correlate(ms)\n",
    "        if normalized == True:\n",
    "            norm = np.cumsum(ms,axis=0)[::-1]\n",
    "            norm /= (1.+np.arange(norm.shape[0])[::-1]).reshape(norm.shape[0],1)\n",
    " \n",
    "        return corr, norm\n",
    "\n",
    "        \n",
    "    def survival_continuous(self,ms,normalized):\n",
    "        norm = None\n",
    "        n_part = len(ms[0])\n",
    "        corr = np.zeros((self.nseries,n_part))\n",
    "        for part in range(n_part):\n",
    "            edges = np.where(ms[::,part][:-1] != ms[::,part][1:])[0]\n",
    "            deltat = edges[1::2]-edges[0::2]\n",
    "            for dt in deltat: # for each of the disconnected segments\n",
    "                              # no need to compute the correlation, we know what it is\n",
    "                              # (already normalized...)\n",
    "                corr[0:dt,part] += 1./len(deltat)\n",
    "                \n",
    "        return corr, np.array( [ [1] * n_part ] ) # to be consistent, will average to one\n",
    "    \n",
    "    \n",
    "    def autocorrelation_continuous(self, ts, ms):\n",
    "\n",
    "        dim = self.dim \n",
    "        norm = None\n",
    "        n_part = len(ms[0])\n",
    "        corr = np.zeros(ts.shape)\n",
    "        for part in range(n_part):\n",
    "            edges = np.where(ms[::,part][:-1] != ms[::,part][1:])[0]\n",
    "            deltat = edges[1::2]-edges[0::2]\n",
    "            for ind,dt in enumerate(deltat): # for each of the disconnected segments\n",
    "                              # no need to compute the correlation, we know what it is\n",
    "                              # (already normalized...)\n",
    "                t1 = edges[2*ind]\n",
    "                t2 = edges[2*ind+1]\n",
    "                i1 = dim*part\n",
    "                i2 = dim*(part+1)\n",
    "                corr[0:dt,i1:i2] += utilities.correlate(ts[t1:t2,i1:i2])/len(deltat)\n",
    "                \n",
    "        return corr,corr[:,0] # to be consistent, will average to one\n",
    "    \n",
    "    def correlation_(self, reduced = False, normalized = True, exact = True, intermittent = True):\n",
    "      \n",
    "        self.dim = determine_dimension(self)\n",
    "\n",
    "        # the standard correlation \n",
    "        if self.reference is None :\n",
    "            corr = utilities.correlate(ts)\n",
    "            norm = corr[:,0]\n",
    "            if reduced == True :\n",
    "                corr = np.average(corr,axis=1)\n",
    "                norm = corr[0]\n",
    "            if normalized == True:\n",
    "                corr /= norm\n",
    "            return corr\n",
    "\n",
    "        # prepare the mask for the intermittent/continuous cases\n",
    "        if intermittent == True:\n",
    "            ms = np.asarray(self.maskseries,dtype=np.double)\n",
    "        else: # we add Falses at the begining and at the end to ease the splitting in sub-trajectories\n",
    "            falses = [[False] * len(nn.maskseries[0])]\n",
    "            ms = np.asarray(falses+self.maskseries+falses)\n",
    "\n",
    "        # compute the survival probabily\n",
    "        if self.observable is None:  \n",
    "            return survival_probability(self,ms,normalized,reduced,intermittent)\n",
    "        # compute the autocorrelation function \n",
    "        else:\n",
    "            ts = np.asarray(self.timeseries)\n",
    "            return autocorrelation(self,ts, ms, normalized, reduced, intermittent)\n",
    "\n",
    "    def  autocorrelation(self,ts, ms, normalized, reduced, intermittent):\n",
    "\n",
    "        if intermittent == True:\n",
    "            corr, norm = autocorrelation_intermittent(self,ts,ms)\n",
    "        else:\n",
    "            corr, norm = autocorrelation_continuous(self,ts,ms)\n",
    "        if reduced == True:\n",
    "            corr = np.average(corr,axis=1)\n",
    "        if normalized == True:\n",
    "            corr /= corr[0]  \n",
    "            \n",
    "        return corr\n",
    "\n",
    "    \n",
    "    def autocorrelation_intermittent(self,ts,ms):\n",
    "        \n",
    "        dim = self.dim\n",
    "\n",
    "        \n",
    "        maskcorr = utilities.correlate(ms)\n",
    "        cond = np.where(maskcorr>1e-9)\n",
    "        corr = ts.copy()\n",
    "        for xyz in range(dim):\n",
    "            corr[:,xyz::dim] = utilities.correlate(ts[:,xyz::dim]*ms)\n",
    "            corr[:,xyz::dim][cond] /=  maskcorr[cond]\n",
    "            #corr[:,xyz::dim][~cond] = 0.0\n",
    "\n",
    "        norm = corr[:,0]\n",
    "  \n",
    "        return corr, norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print np.around(-0.0,decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0 == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75 ,  0.625],\n",
       "       [ 0.75 , -0.   ],\n",
       "       [ 0.5  ,  0.5  ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.correlation(reduced=False,normalized=False,intermittent=  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.688,  0.375,  0.5  ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.correlation(reduced=True,normalized=False,intermittent=  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75   0.625]\n",
      " [ 0.75  -0.   ]\n",
      " [ 0.5    0.5  ]]\n"
     ]
    }
   ],
   "source": [
    "print      correlation_(vv, reduced = False, normalized = False, exact = True, intermittent = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2]\n",
      " [2 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print np.cumsum(nn.maskseries,axis=0)/np.arange(nn.maskseries.sa)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
